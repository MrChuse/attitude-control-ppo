{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7d17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6fa90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = SimpleNamespace()\n",
    "const.mu = 3.986e14\n",
    "const.Re = 6037.1e3\n",
    "sat = SimpleNamespace()\n",
    "sat.J = np.diag(np.array([4, 5, 3]))\n",
    "sat.J_inv = np.linalg.inv(sat.J)\n",
    "sat.altitude = 600e3\n",
    "sat.mean_motion = np.sqrt(const.mu / (const.Re + sat.altitude)**3.)\n",
    "\n",
    "\n",
    "class TorqueDynamics(gym.Env):\n",
    "  observation_space = gym.spaces.Box(-1, 1, shape=(10,))\n",
    "\n",
    "  \n",
    "  def __init__(self, dt, q_req, add_9=0.25):\n",
    "    self.state = None\n",
    "    self.dt = dt\n",
    "    self.q_req = q_req\n",
    "    self.q_req_conj = quat_conjugate(self.q_req)\n",
    "    self.w_req = np.zeros(3)\n",
    "    self.history = []\n",
    "    self.t = []\n",
    "    self.action_space = self.init_actions()\n",
    "    self.q_prev = None\n",
    "    self.add_9 = add_9\n",
    "\n",
    "  @staticmethod\n",
    "  def init_actions():\n",
    "    a = np.linspace(-1, 1, 21)\n",
    "    a1 = a/10\n",
    "    a2 = a/100\n",
    "    a = np.concatenate((a, a1, a2))\n",
    "    a = np.unique(a.round(10))\n",
    "    a = a[a>=-0.5]\n",
    "    a = a[a<=0.5]\n",
    "\n",
    "    s = a.shape\n",
    "    a = np.vstack((a, np.zeros(s)))\n",
    "    a = np.vstack((a, np.zeros(s)))\n",
    "    a = a.T\n",
    "    aroll1 = np.roll(a, 1)\n",
    "    aroll2 = np.roll(a, 2)\n",
    "    a = np.concatenate((a, aroll1))\n",
    "    a = np.concatenate((a, aroll2))\n",
    "    a = np.unique(a, axis=0)\n",
    "    return a\n",
    "\n",
    "  def reset(self, state=None):\n",
    "    if state is not None:\n",
    "      self.state = state\n",
    "    else:\n",
    "      self.state = self.observation_space.sample()\n",
    "      phi = self.state[0] * np.pi \n",
    "      self.state[0] = np.cos(phi / 2)\n",
    "      self.state[1:4] = normalize(self.state[1:4]) * np.sin(phi / 2)\n",
    "      self.state[4:] = 0\n",
    "    self.history = [self.state]\n",
    "    self.t = [0]\n",
    "    self.q_prev = self.state[:4]\n",
    "    self.multiplier = 1\n",
    "    return self.state\n",
    "\n",
    "  @staticmethod\n",
    "  def r_a(phi, q_current, q_prev):\n",
    "    return np.exp(2-phi) if q_current > q_prev else np.exp(2-phi)/2\n",
    "\n",
    "\n",
    "  def r_t(self, reward, phi):\n",
    "    return reward + 9 if phi <= self.add_9 else reward\n",
    "\n",
    "  def step(self, action):\n",
    "    t0 = 0\n",
    "    tf = self.dt\n",
    "    x_0 = self.state\n",
    "    if isinstance(action, int) or isinstance(action, np.int64):\n",
    "      action = self.action_space[action].copy()\n",
    "    \n",
    "    action *= self.multiplier\n",
    "    \n",
    "    sol = solve_ivp(lambda t, x: rhs(t, x, sat, action), (t0,tf), x_0)#, t_eval=t_eval)\n",
    "    x = sol.y.T\n",
    "    t = sol.t[1:]\n",
    "    observation = x[-1]\n",
    "    observations = normalize(observation)\n",
    "    time_ = self.t[-1] + self.dt\n",
    "    self.state = observation\n",
    "    self.history.append(observation)\n",
    "    self.t.append(time_)\n",
    "\n",
    "    # calculating rewards:\n",
    "    q_current = observation[:4]\n",
    "    q_error = quat_product(self.q_req_conj, q_current)\n",
    "    q_error = np.clip(q_error, -1, 1)\n",
    "    w_current = observation[4:7]\n",
    "    #print('q_error', q_error)\n",
    "    phi = 2*np.arccos(q_error[0])\n",
    "    r_inter = self.r_a(phi, q_current[0], self.q_prev[0])\n",
    "    r1 = self.r_t(r_inter, phi)\n",
    "    # r2 = -np.sum(np.abs(observation[4:7]))\n",
    "    # Qreward = np.exp(-0.1 * np.linalg.norm(q_current - self.q_req))\n",
    "    # Wreward = np.exp(-0.1 * np.linalg.norm(w_current - self.w_req))\n",
    "    # reward = Qreward * Wreward\n",
    "    # reward = self.r_t(reward, phi)\n",
    "    reward = r_inter #r1 #+ 10 * r2\n",
    "    #print('rewards', r1, r2)\n",
    "    \n",
    "    self.multiplier = 1 if phi > np.pi/8 else np.sin(4*phi)\n",
    "    \n",
    "    self.q_prev = q_current\n",
    "\n",
    "    q_req_ext = np.concatenate([self.q_req, self.w_req])\n",
    "    done = np.linalg.norm(observation[:7] - q_req_ext) < 1e-4\n",
    "    \n",
    "    info = dict()\n",
    "    info['x'] = self.history\n",
    "    info['t'] = self.t\n",
    "    return observation, reward, done, info\n",
    "  \n",
    "  def render(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7ded9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
